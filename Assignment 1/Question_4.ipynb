{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reason for using Confirmed case for finding peak\n",
    "\n",
    "Lets assume at peak rate of new cases was equal to 300K per day<br>\n",
    "<br>\n",
    "Current senario:<br>\n",
    "Rate of new cases : 10K per day<br>\n",
    "Rate of recovery : 10K per day<br>\n",
    "Total Active cases : 100K <br><br>\n",
    "Now the virus mutated such the rate of recovery reduced to 0 per day but rate of new cases is constant(10K). After 10 days total active cases reached to 200K.\n",
    "<br><br>But after arival of new method treatment is used and the rate of recovery increased to 20K per day. That means after 10 days total active will become 100K.<br> <br>\n",
    "So it is clearly visible that there is first increase in active cases and then decrease this implies a peak but it is not considered as peak because the rate of new cases is constant.<br><br>\n",
    "From above example we can say that rate of new cases is directly proportional to peak value and there may be chances that active cases may play some role in peak but that is not considerable.<br><br>\n",
    "That is why I am using Daily Confirmed case for finding peak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method of finding the peak\n",
    "1. For finding two peaks I first divide the complete weeks(months) into two equal parts\n",
    "2. In each parts I first use **moving average** for finding the average number of maximum cases in period of 20 weeks. In case of month using period of 3 months for average for finding the peak.\n",
    "3. Now after finding the period find the exact week (month) which corresponds as peak.\n",
    "4. Final answer is added with 1 because index starts from 0.\n",
    "5. Weekid may be confusing because we are using overlaped week so get the actual week number we have to divide the weekid by 2 take ceil value of it(Not doing this beacuse that will completely distory the whole meaning of overlapped week. But same result is produced using non-overlapped weeks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing State \n",
    "\n",
    "In state-peak.csv some state are missing because their districts are unknown and after droping(as per sir discussed in class) we are left with some missing state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets from previous Question i.e., Question_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week_district = pd.read_csv(\"Dataset/Additional Files/cases-week-overlaped-district.csv\")\n",
    "df_month_district = pd.read_csv(\"Dataset/Output Files/cases-month.csv\")\n",
    "df_week_state = pd.read_csv(\"Dataset/Additional Files/cases-week-overlap-state.csv\")\n",
    "df_month_state = pd.read_csv(\"Dataset/Additional Files/cases-month-state.csv\")\n",
    "df_week_overall = pd.read_csv(\"Dataset/Additional Files/cases-week-overlap-overall.csv\")\n",
    "df_month_overall = pd.read_csv(\"Dataset/Additional Files/cases-month-overall.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ditrict Wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_district = list(df_week_district[\"districtid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "district = []\n",
    "week1 = []\n",
    "week2 = []\n",
    "\n",
    "for dis in unique_district:\n",
    "    \n",
    "    \n",
    "    cases = list(df_week_district[df_week_district[\"districtid\"] == dis][\"cases\"])\n",
    "    if np.sum(cases) == 0:\n",
    "        continue\n",
    "    avg_cases = []\n",
    "    \n",
    "    #Dividing the complete list into two equal parts\n",
    "    mid = len(cases) // 2\n",
    "    \n",
    "    #Calculating the average number of cases in peirod of 20 weeks\n",
    "    for i in range(len(cases) - 20):\n",
    "        avg_cases.append(np.mean(cases[i : i + 20]))\n",
    "    \n",
    "    #Finding the period which has average maximum number of cases\n",
    "    max_avg_idx_1 = np.argmax(avg_cases[ : mid])\n",
    "    max_avg_idx_2 = mid + np.argmax(avg_cases[mid : ])\n",
    "    \n",
    "    #Finding the exact value of weekid \n",
    "    week_1 = max_avg_idx_1 +np.argmax(cases[max_avg_idx_1: max_avg_idx_1 + 20]) + 1\n",
    "    week_2 = max_avg_idx_2 + np.argmax(cases[max_avg_idx_2: max_avg_idx_2 + 20]) + 1\n",
    "    \n",
    "    district.append(dis)\n",
    "    #appending final result to respective list \n",
    "    week1.append(week_1)\n",
    "    week2.append(week_2)\n",
    "    \n",
    "#Converting list to dataframe and then sorting according to District id    \n",
    "peak_week_dist  = {\"districtid\" : district, \"wave1 - weekid\" : week1, \"wave2 - weekid\" : week2}\n",
    "peak_week_district = pd.DataFrame(peak_week_dist)\n",
    "peak_week_district.sort_values(by = [\"districtid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "district = []\n",
    "month1 = []\n",
    "month2 = []\n",
    "\n",
    "for dis in unique_district:\n",
    "    #print(dis)\n",
    "    \n",
    "    cases = list(df_month_district[df_month_district[\"districtid\"] == dis][\"cases\"])\n",
    "    if np.sum(cases) == 0:\n",
    "        continue\n",
    "    avg_cases = []\n",
    "    \n",
    "    #Dividing the complete list into two equal parts\n",
    "    mid = len(cases) // 2\n",
    "    \n",
    "    #Calculating the average number of cases in peirod of 3 Months\n",
    "    for i in range(len(cases) - 3):\n",
    "        avg_cases.append(np.mean(cases[i : i + 3]))\n",
    "        \n",
    "    #Finding the period which has average maximum number of cases\n",
    "    max_avg_idx_1 = np.argmax(avg_cases[ : mid])\n",
    "    max_avg_idx_2 = mid + np.argmax(avg_cases[mid : ])\n",
    "    \n",
    "    #Finding the exact value of monthid    \n",
    "    month_1 = max_avg_idx_1 + np.argmax(cases[max_avg_idx_1: max_avg_idx_1 + 3]) + 1\n",
    "    month_2 = max_avg_idx_2 + np.argmax(cases[max_avg_idx_2: max_avg_idx_2 + 3]) + 1\n",
    "    \n",
    "    #appending final result to respective list \n",
    "    district.append(dis)\n",
    "    month1.append(month_1)\n",
    "    month2.append(month_2)\n",
    "    \n",
    " #Converting list to dataframe and then sorting according to District id   \n",
    "peak_month_dist  = {\"districtid\" : district, \"wave1 - monthid\" : month1, \"wave2 - monthid\" : month2}\n",
    "peak_month_district = pd.DataFrame(peak_month_dist)\n",
    "peak_month_district.sort_values(by = [\"districtid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging  **peak_week_district** and **peak_month_district** into **peak_district**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_district = pd.merge(peak_week_district, peak_month_district)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_state = set(df_week_state[\"stateid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = []\n",
    "week1 = []\n",
    "week2 = []\n",
    "\n",
    "for st in unique_state:\n",
    "    \n",
    "    cases = list(df_week_state[df_week_state[\"stateid\"] == st][\"cases\"])\n",
    "    if np.sum(cases) == 0:\n",
    "        continue\n",
    "    avg_cases = []\n",
    "    \n",
    "    #Dividing the complete list into two equal parts\n",
    "    mid = len(cases) // 2\n",
    "    \n",
    "    #Calculating the average number of cases in peirod of 20 weeks\n",
    "    for i in range(len(cases) - 20):\n",
    "        avg_cases.append(np.mean(cases[i : i + 20]))\n",
    "        \n",
    "    #Finding the period which has average maximum number of cases\n",
    "    max_avg_idx_1 = np.argmax(avg_cases[ : mid])\n",
    "    max_avg_idx_2 = mid + np.argmax(avg_cases[mid : ])\n",
    "    \n",
    "    #Finding the exact value of weekid \n",
    "    week_1 = max_avg_idx_1 +np.argmax(cases[max_avg_idx_1: max_avg_idx_1 + 20]) + 1\n",
    "    week_2 = max_avg_idx_2 + np.argmax(cases[max_avg_idx_2: max_avg_idx_2 + 20]) + 1\n",
    "    \n",
    "    #appending final result to respective list \n",
    "    state.append(st)\n",
    "    week1.append(week_1)\n",
    "    week2.append(week_2)\n",
    "    \n",
    "#Converting list to dataframe and then sorting according to State id    \n",
    "peak_week_state_dist  = {\"stateid\" : state, \"wave1 - weekid\" : week1, \"wave2 - weekid\" : week2}\n",
    "peak_week_state_df = pd.DataFrame(peak_week_state_dist)\n",
    "peak_week_state_df.sort_values(by = [\"stateid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = []\n",
    "month1 = []\n",
    "month2 = []\n",
    "\n",
    "for st in unique_state:\n",
    "    \n",
    "    cases = list(df_month_state[df_month_state[\"stateid\"] == st][\"cases\"])\n",
    "    if np.sum(cases) == 0:\n",
    "        continue\n",
    "    avg_cases = []\n",
    "    \n",
    "    #Dividing the complete list into two equal parts\n",
    "    mid = len(cases) // 2\n",
    "    \n",
    "    #Calculating the average number of cases in peirod of 3 Months\n",
    "    for i in range(len(cases) - 3):\n",
    "        avg_cases.append(np.mean(cases[i : i + 3]))\n",
    "        \n",
    "    #Finding the period which has average maximum number of cases\n",
    "    max_avg_idx_1 = np.argmax(avg_cases[ : mid])\n",
    "    max_avg_idx_2 = mid + np.argmax(avg_cases[mid : ])\n",
    "    \n",
    "    #Finding the exact value of monthid    \n",
    "    month_1 = max_avg_idx_1 + np.argmax(cases[max_avg_idx_1: max_avg_idx_1 + 3]) + 1\n",
    "    month_2 = max_avg_idx_2 + np.argmax(cases[max_avg_idx_2: max_avg_idx_2 + 3]) + 1\n",
    "    \n",
    "    #appending final result to respective list \n",
    "    state.append(st)\n",
    "    month1.append(month_1)\n",
    "    month2.append(month_2)\n",
    "    \n",
    "#Converting list to dataframe and then sorting according to State id        \n",
    "peak_month_state_dist  = {\"stateid\" : state, \"wave1 - monthid\" : month1, \"wave2 - monthid\" : month2}\n",
    "peak_month_state_df = pd.DataFrame(peak_month_state_dist)\n",
    "peak_month_state_df.sort_values(by = [\"stateid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging  **peak_week_state_df** and **peak_month_state_df** into **peak_state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_state = pd.merge(peak_week_state_df, peak_month_state_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cases = []\n",
    "cases = list(df_week_overall[\"cases\"])\n",
    "\n",
    "#Dividing the complete list into two equal parts\n",
    "mid = len(cases) // 2\n",
    "\n",
    "#Calculating the average number of cases in peirod of 20 weeks\n",
    "for i in range(len(cases) - 20):\n",
    "    avg_cases.append(np.mean(cases[i : i + 20]))\n",
    "    \n",
    "#Finding the period which has average maximum number of cases\n",
    "max_avg_idx_1 = np.argmax(avg_cases[ : mid])\n",
    "max_avg_idx_2 = mid + np.argmax(avg_cases[mid : ])\n",
    "\n",
    "#Finding the exact value of weekid \n",
    "week_1 = max_avg_idx_1 + np.argmax(cases[max_avg_idx_1: max_avg_idx_1 + 20]) + 1\n",
    "week_2 = max_avg_idx_2 + np.argmax(cases[max_avg_idx_2: max_avg_idx_2 + 20]) + 1\n",
    "\n",
    "#Converting list to dataframe\n",
    "peak_week_country_dist  = {\"country\" : \"India\", \"wave1 - weekid\" : [week_1], \"wave2 - weekid\" : [week_2]}\n",
    "peak_week_country_df = pd.DataFrame(peak_week_country_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = list(df_month_overall[\"cases\"])\n",
    "\n",
    "avg_cases = []\n",
    "\n",
    "#Dividing the complete list into two equal parts\n",
    "mid = len(cases) // 2\n",
    "\n",
    "#Calculating the average number of cases in peirod of 3 Months\n",
    "for i in range(len(cases) - 3):\n",
    "    avg_cases.append(np.mean(cases[i : i + 3]))\n",
    "    \n",
    "#Finding the period which has average maximum number of cases    \n",
    "max_avg_idx_1 = np.argmax(avg_cases[ : mid])\n",
    "max_avg_idx_2 = mid + np.argmax(avg_cases[mid : ])\n",
    "\n",
    " #Finding the exact value of monthid    \n",
    "month_1 = max_avg_idx_1 + np.argmax(cases[max_avg_idx_1: max_avg_idx_1 + 3]) + 1\n",
    "month_2 = max_avg_idx_2 + np.argmax(cases[max_avg_idx_2: max_avg_idx_2 + 3]) + 1\n",
    "\n",
    "#Converting list to dataframe\n",
    "peak_month_country_dist  = {\"country\" : \"India\", \"wave1 - monthid\" : [month_1], \"wave2 - monthid\" : [month_2]}\n",
    "peak_month_country_df = pd.DataFrame(peak_month_country_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging  **peak_week_country_df** and **peak_month_country_df** into **peak_overall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_overall = pd.merge(peak_week_country_df, peak_month_country_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Final Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**district-peak.csv**  : District wise peak values<br>\n",
    "**state-peak.csv**  : State wise peak values<br>\n",
    "**overall-peak.csv**  : Overall wise peak values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_district.to_csv(\"Dataset/Output Files/district-peaks.csv\", index=False)\n",
    "peak_state.to_csv(\"Dataset/Output Files/state-peaks.csv\", index=False)\n",
    "peak_overall.to_csv(\"Dataset/Output Files/overall-peaks.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
